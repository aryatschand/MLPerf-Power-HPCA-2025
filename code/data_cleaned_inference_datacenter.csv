Public ID,Organization,SystemType,SystemName,Model,Model MLC,Scenario,Result,number_of_nodes,host_processor_model_name,host_processors_per_node,accelerator_model_name,accelerators_per_node,Software,operating_system,notes,version,date,vdate,Units,Total Accelerators
2.0-020,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,117002,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,500W A100-SXM-80GB,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-020,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,1413.775,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,500W A100-SXM-80GB,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-020,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,126205,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,500W A100-SXM-80GB,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-020,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,1385.60906,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,500W A100-SXM-80GB,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),ResNet,ResNet,Server,2342.3,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),ResNet,ResNet,Server,230.2302333,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),ResNet,ResNet,Offline,3012.76,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),ResNet,ResNet,Offline,281.1463444,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),RNN-T,RNN-T,Server,652.49,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),RNN-T,RNN-T,Server,305.5364725,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),RNN-T,RNN-T,Offline,1006.3,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),RNN-T,RNN-T,Offline,306.5049008,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,149.993,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,279.3510309,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,244.643,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,302.861365,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,59.9971,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,222.3039563,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,119.573,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,293.0224434,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,11989.8,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,219.9021833,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,22034.9,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,293.295968,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,11989.8,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,219.9021833,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,22034.9,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,1.0
2.0-022,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,293.295968,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),1.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,22.8274,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,3378.849351,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,22.8274,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,3378.849351,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,81993.6,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,3393.748,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,97064.5,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,3419.545147,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,16489.7,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,3373.143636,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,23898.3,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,3419.123485,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,8244.89,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3409.410579,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,11883.2,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,3431.658584,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,1400980,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,3067.569833,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,2124460,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,3266.607891,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,1400980,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,3067.569833,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,2124460,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-032,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-40GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,3266.607891,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM4-40GB,8.0,TensorRT 8.4.0; CUDA 11.6,,Maximum GPU power is limitted to 275W with nvidia-smi command,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),ResNet,ResNet,Server,265029,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),ResNet,ResNet,Server,1348.775167,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),ResNet,ResNet,Offline,311873,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),ResNet,ResNet,Offline,1532.393643,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),SSD-Large,SSD-Large,Server,6078.03,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),SSD-Large,SSD-Large,Server,1493.6235,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),SSD-Large,SSD-Large,Offline,6155.78,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),SSD-Large,SSD-Large,Offline,1507.102899,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),BERT-99.0,BERT-99.0,Server,9594.98,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),BERT-99.0,BERT-99.0,Server,1361.895667,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),BERT-99.0,BERT-99.0,Offline,10045.8,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),BERT-99.0,BERT-99.0,Offline,1371.413344,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),BERT-99.9,BERT-99.9,Server,4448.17,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),BERT-99.9,BERT-99.9,Server,1215.170667,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),BERT-99.9,BERT-99.9,Offline,4629.87,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,16.0
2.0-035,GIGABYTE,datacenter,Gigabyte G292-Z43 (16x QAIC100; EE),BERT-99.9,BERT-99.9,Offline,1203.724776,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),16.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),ResNet,ResNet,Server,94996.9,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),ResNet,ResNet,Server,484.5092667,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),ResNet,ResNet,Offline,97527.3,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),ResNet,ResNet,Offline,491.4624085,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),SSD-Large,SSD-Large,Server,1849.43,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),SSD-Large,SSD-Large,Server,466.62295,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),SSD-Large,SSD-Large,Offline,1927.75,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),SSD-Large,SSD-Large,Offline,479.1455692,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),BERT-99.0,BERT-99.0,Server,2848.1,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),BERT-99.0,BERT-99.0,Server,424.3088686,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),BERT-99.0,BERT-99.0,Offline,3142.52,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),BERT-99.0,BERT-99.0,Offline,438.9852842,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),BERT-99.9,BERT-99.9,Server,1300.33,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),BERT-99.9,BERT-99.9,Server,397.7072333,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),BERT-99.9,BERT-99.9,Offline,1448.92,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,5.0
2.0-053,Krai,datacenter,Gigabyte R282-Z93 (5x QAIC100; EE),BERT-99.9,BERT-99.9,Offline,407.978017,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,5.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),5.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),ResNet,ResNet,Server,176002,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),ResNet,ResNet,Server,828.7415,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),ResNet,ResNet,Offline,179188,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),ResNet,ResNet,Offline,823.9321086,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),SSD-Large,SSD-Large,Server,3527.25,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),SSD-Large,SSD-Large,Server,827.0035,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),SSD-Large,SSD-Large,Offline,3607.83,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),SSD-Large,SSD-Large,Offline,830.8429017,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),BERT-99.0,BERT-99.0,Server,5511.75,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),BERT-99.0,BERT-99.0,Server,790.6185,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),BERT-99.0,BERT-99.0,Offline,5745.17,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),BERT-99.0,BERT-99.0,Offline,794.3025074,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),BERT-99.9,BERT-99.9,Server,2667.85,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),BERT-99.9,BERT-99.9,Server,723.8395,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),BERT-99.9,BERT-99.9,Offline,2906.84,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-054,Krai,datacenter,Gigabyte R282-Z93 (8x QAIC100),BERT-99.9,BERT-99.9,Offline,740.2835866,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),ResNet,ResNet,Server,92496.2,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),ResNet,ResNet,Server,985.2238333,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),ResNet,ResNet,Offline,104893,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),ResNet,ResNet,Offline,997.0415894,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,2748.21,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,1109.539167,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,2893.91,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,1124.541755,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,9.64701,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,996.9325755,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,9.64701,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,996.9325755,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),RNN-T,RNN-T,Server,37488.9,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),RNN-T,RNN-T,Server,1139.777537,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),RNN-T,RNN-T,Offline,42945.2,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),RNN-T,RNN-T,Offline,1134.323941,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,9994.96,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,1250.4545,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,10046.6,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,1247.151294,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3997.54,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,1238.5675,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,4991.01,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,1252.68716,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,500121,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,1222.924833,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,953749,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,1240.553765,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,500121,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,1222.924833,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,953749,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-078,NVIDIA,datacenter,Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,1240.553765,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-PCIe-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,185005,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,2085.769333,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,211065,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,1860.642933,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,5696.82,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,2094.343167,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,5778.3,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,2101.287009,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,19.4206,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,1859.590379,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,19.4206,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,1859.590379,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,74989.7,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,2199.541167,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,85951.8,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,2195.113459,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,17291.6,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,2137.032667,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,19993.2,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,2361.508909,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,7494.89,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,2142.023627,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,9988.62,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,2370.24553,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,750272,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,2090.183833,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,1845900,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,2319.945364,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,750272,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,2090.183833,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,1845900,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-081,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,2319.945364,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),ResNet,ResNet,Server,230018,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),ResNet,ResNet,Server,2821.629333,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),ResNet,ResNet,Offline,268462,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),ResNet,ResNet,Offline,2815.234959,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,6297.67,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,2823.106167,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,6520.82,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,2825.303392,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,19.9718,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,2377.159497,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,19.9718,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,2377.159497,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),RNN-T,RNN-T,Server,74989.7,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),RNN-T,RNN-T,Server,2843.6995,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),RNN-T,RNN-T,Offline,90946.4,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),RNN-T,RNN-T,Offline,2852.17763,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,20991.6,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,3242.228053,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,20705.9,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,2806.716548,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,8794.88,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3230.908804,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,9857.47,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,2808.491667,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,1831680,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,2813.629167,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,1940830,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,2766.558529,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,1831680,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,2813.629167,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,1940830,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-084,NVIDIA,datacenter,Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,2766.558529,1.0,Ampere Altra Q80-30,1.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,229016,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,2910.199167,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,250242,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,2885.12732,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,6297.67,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,3128.114667,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,6575.98,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,3109.665729,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,21.4415,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,2926.223519,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,21.4415,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,2926.223519,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,87991.6,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,3454.833667,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,90730,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,3247.560898,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,21491.7,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,3378.760956,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,24793.7,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,3544.703504,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,9994.96,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3409.606271,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,11402.8,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,3344.572684,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,2001990,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,3372.277704,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,2140540,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,3312.372838,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,2001990,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,3372.277704,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,2140540,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-095,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,3312.372838,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,107000,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,1131.176833,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,128665,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,1131.814206,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,3077.88,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,1231.252833,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,3307.43,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,1240.456136,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,10.7783,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,1136.778318,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,10.7783,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,1136.778318,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,43388.3,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,1294.00599,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,44966,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,1187.381108,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,10194.7,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,1272.193833,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,10827.7,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,1253.528197,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,4297.74,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,1270.586333,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,5233.53,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,1252.89271,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,870363,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,1340.061167,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,1001010,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,1255.04264,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,870363,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,queries/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,1340.061167,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,1001010,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,samples/s,4.0
2.0-098,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,1255.04264,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 8.4.0; CUDA 11.6,,,v2.0,4/27/2022,Inference v2.0,System Power (W),4.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),ResNet,ResNet,Server,273027,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),ResNet,ResNet,Server,1404.182,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),ResNet,ResNet,Offline,337433,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),ResNet,ResNet,Offline,1605.890924,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),SSD-Large,SSD-Large,Server,6098.2,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),SSD-Large,SSD-Large,Server,1581.3065,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),SSD-Large,SSD-Large,Offline,6822,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),SSD-Large,SSD-Large,Offline,1667.38046,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),BERT-99.0,BERT-99.0,Server,10793.5,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),BERT-99.0,BERT-99.0,Server,1486.391181,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),BERT-99.0,BERT-99.0,Offline,11305.6,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),BERT-99.0,BERT-99.0,Offline,1439.021963,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),BERT-99.9,BERT-99.9,Server,4797.61,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),BERT-99.9,BERT-99.9,Server,1309.154833,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),BERT-99.9,BERT-99.9,Offline,5254.36,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,18.0
2.0-124,Qualcomm,datacenter,Gigabyte G292-Z43 (18x QAIC100; EE),BERT-99.9,BERT-99.9,Offline,1294.427106,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),18.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),ResNet,ResNet,Server,150999,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),ResNet,ResNet,Server,663.0713333,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),ResNet,ResNet,Offline,155761,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),ResNet,ResNet,Offline,677.2303835,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),SSD-Large,SSD-Large,Server,2997.58,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),SSD-Large,SSD-Large,Server,629.1885,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),SSD-Large,SSD-Large,Offline,3110.26,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),SSD-Large,SSD-Large,Offline,640.9897561,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),BERT-99.0,BERT-99.0,Server,4697.46,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),BERT-99.0,BERT-99.0,Server,574.9969667,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),BERT-99.0,BERT-99.0,Offline,5049.7,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),BERT-99.0,BERT-99.0,Offline,593.6849923,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),BERT-99.9,BERT-99.9,Server,2098.48,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,queries/s,8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),BERT-99.9,BERT-99.9,Server,525.5452167,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),BERT-99.9,BERT-99.9,Offline,2335.47,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,samples/s,8.0
2.0-126,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100; EE),BERT-99.9,BERT-99.9,Offline,547.8050708,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,Qualcomm Cloud AI SDK v1.6.80,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1,v2.0,4/27/2022,Inference v2.0,System Power (W),8.0
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),ResNet,ResNet,Server,2631.3,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),ResNet,ResNet,Server,252.9491667,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),ResNet,ResNet,Offline,3091.84,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),ResNet,ResNet,Offline,266.9385801,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),RNN-T,RNN-T,Server,649.987,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),RNN-T,RNN-T,Server,291.7138833,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),RNN-T,RNN-T,Offline,1166.32,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),RNN-T,RNN-T,Offline,292.9018433,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,149.674,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,248.590473,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,245.351,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,284.6892113,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,59.8697,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,212.1589597,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,118.222,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,282.3882521,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,19986.2,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,265.3701333,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,22172.1,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,275.1581611,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,19986.2,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,265.3701333,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,22172.1,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,1
2.1-0011,Dell,datacenter,Dell PowerEdge XR12 (1x A2; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,275.1581611,1.0,Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz,1.0,NVIDIA A2,1,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),1
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,128029,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,queries/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,1464.218833,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,131364,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,1390.987544,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,1796.17,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,queries/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,1488.908833,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,2019.47,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,1506.429207,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,10.5661,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,1325.90116,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,10.5661,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,1325.90116,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,47997.8,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,queries/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,1695.087687,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,45521.6,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,1600.324039,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,10495.2,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,queries/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,1608.973388,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,11594.1,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,1579.691564,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,5296.66,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,queries/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,1771.642149,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,5475.96,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0015,Dell,datacenter,Dell PowerEdge XE8545 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,1576.281826,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB CTS,4,TensorRT 8.4.2; CUDA 11.6,,NVIDIA A100-SXM-80GB (TDP: 500W),v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),ResNet,ResNet,Server,91206.6,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,queries/s,4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),ResNet,ResNet,Server,512.2853667,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),ResNet,ResNet,Offline,92235.4,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),ResNet,ResNet,Offline,502.1539907,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),BERT-99.0,BERT-99.0,Server,2550.92,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,queries/s,4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),BERT-99.0,BERT-99.0,Server,455.2483167,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),BERT-99.0,BERT-99.0,Offline,2913,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),BERT-99.0,BERT-99.0,Offline,476.3084615,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),BERT-99.9,BERT-99.9,Server,1277.56,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,queries/s,4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),BERT-99.9,BERT-99.9,Server,434.7384833,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),BERT-99.9,BERT-99.9,Offline,1394.35,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,samples/s,4
2.1-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),BERT-99.9,BERT-99.9,Offline,433.9564889,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),4
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),ResNet,ResNet,Server,266066,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),ResNet,ResNet,Server,3244.619,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),ResNet,ResNet,Offline,297046,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),ResNet,ResNet,Offline,3310.028742,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),Retinanet,Retinanet,Server,2495.29,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),Retinanet,Retinanet,Server,2856.619167,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),Retinanet,Retinanet,Offline,4263.58,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),Retinanet,Retinanet,Offline,3341.780176,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,24.1462,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,3425.591945,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,24.1462,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,3425.591945,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),RNN-T,RNN-T,Server,94558.3,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),RNN-T,RNN-T,Server,3499.8225,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),RNN-T,RNN-T,Offline,95851.8,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),RNN-T,RNN-T,Offline,3514.44544,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),BERT-99.0,BERT-99.0,Server,21988.7,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),BERT-99.0,BERT-99.0,Server,3482.632125,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),BERT-99.0,BERT-99.0,Offline,23319.7,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),BERT-99.0,BERT-99.0,Offline,3413.074676,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),BERT-99.9,BERT-99.9,Server,9994.91,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),BERT-99.9,BERT-99.9,Server,3478.008911,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),BERT-99.9,BERT-99.9,Offline,11035.8,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0019,Fujitsu,datacenter,PRIMERGY GX2570M6 (8x A100-SXM-80GB; TensorRT),BERT-99.9,BERT-99.9,Offline,3419.999088,1.0,Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),ResNet,ResNet,Server,45237.8,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),ResNet,ResNet,Server,898.345,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),ResNet,ResNet,Offline,56970.7,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),ResNet,ResNet,Offline,892.3032806,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),3D-UNet-99.0,3D-UNet-99.0,Offline,5.14164,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),3D-UNet-99.0,3D-UNet-99.0,Offline,1045.115155,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),3D-UNet-99.9,3D-UNet-99.9,Offline,5.14164,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),3D-UNet-99.9,3D-UNet-99.9,Offline,1045.115155,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),RNN-T,RNN-T,Server,12994.7,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),RNN-T,RNN-T,Server,933.4173333,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),RNN-T,RNN-T,Offline,20767.2,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),RNN-T,RNN-T,Offline,926.5191589,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),BERT-99.0,BERT-99.0,Server,4196.94,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),BERT-99.0,BERT-99.0,Server,911.648595,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),BERT-99.0,BERT-99.0,Offline,4835.39,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),BERT-99.0,BERT-99.0,Offline,910.9313507,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),BERT-99.9,BERT-99.9,Server,1796.17,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),BERT-99.9,BERT-99.9,Server,914.2455298,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),BERT-99.9,BERT-99.9,Offline,2373.19,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,3
2.1-0032,H3C,datacenter,H3C UniServer R4900 G5(3x A30; TensorRT; MaxQ),BERT-99.9,BERT-99.9,Offline,911.165721,1.0,Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz,2.0,NVIDIA A30,3,TensorRT 8.4.0; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),3
2.1-0063,Krai,datacenter,Gigabyte G292-Z43 (18x QAIC100 Pro; EE),ResNet,ResNet,Server,250060,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,queries/s,18
2.1-0063,Krai,datacenter,Gigabyte G292-Z43 (18x QAIC100 Pro; EE),ResNet,ResNet,Server,1441.883,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),18
2.1-0063,Krai,datacenter,Gigabyte G292-Z43 (18x QAIC100 Pro; EE),ResNet,ResNet,Offline,357387,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,samples/s,18
2.1-0063,Krai,datacenter,Gigabyte G292-Z43 (18x QAIC100 Pro; EE),ResNet,ResNet,Offline,1723.602762,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),18
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,185047,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,2122.011833,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,252721,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,2068.302297,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,2296.04,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,1905.2415,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,3804.69,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,2193.323369,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,19.4295,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,1795.214613,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,19.4295,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,1795.214613,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,74994.9,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,2213.280366,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,78749.6,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,2025.305224,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,17287.6,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,2163.283833,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,22076.7,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,2546.772817,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,7494.11,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,2169.444667,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,11157.9,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0085,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,2553.835791,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,229055,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,2902.095667,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,288733,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,3082.268468,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,3896.22,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,3120.338167,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,4121.7,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,3112.228232,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,22.5318,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,2925.495604,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,22.5318,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,2925.495604,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,88003.1,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,3458.934609,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,84507.8,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,3041.085978,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,21487.9,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,3378.116007,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,23675.9,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,3336.283612,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,9994.91,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3416.228383,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,11152.1,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,3344.607527,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,2002080,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,3377.699833,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,2128420,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,3316.508871,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,2002080,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,3377.699833,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,2128420,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0089,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,3316.508871,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.4.2; CUDA 11.6,,,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),ResNet,ResNet,Server,151029,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),ResNet,ResNet,Server,723.1886667,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),ResNet,ResNet,Offline,169680,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),ResNet,ResNet,Offline,781.9400322,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Server,5296.66,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Server,595.8976667,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Offline,5597.99,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Offline,613.3228788,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Server,2096.39,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,queries/s,8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Server,549.2228333,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Offline,2445.08,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,samples/s,8
2.1-0102,Qualcomm,datacenter,Gigabyte R282-Z93 (8x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Offline,590.5743704,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8,Qualcomm Cloud AI SDK v1.7.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1,v2.1,9/8/2022,Inference v2.1,System Power (W),8
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),ResNet,ResNet,Server,96015,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),ResNet,ResNet,Server,1446.1595,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),ResNet,ResNet,Offline,109270,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),ResNet,ResNet,Offline,1431.043596,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,2520.26,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,1436.47,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,2587.05,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,1448.128061,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,178.661,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,1478.142784,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,178.661,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,1478.142784,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,7801.53,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,1480.351414,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,7884.1,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,1474.353866,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3551.72,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,1468.538333,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,3738.35,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-006,Dell,datacenter,Dell EMC PowerEdge R750xa (4x A100-PCIE-40GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,1475.88746,1.0,Intel(R) Xeon(R) Platinum 8368 CPU @ 2.40GHz,2.0,NVIDIA A100-PCIE-40GB,4,TensorRT 8.0.2; CUDA 11.3,,Result Measured for Power; GPU Power Limited to 175W,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),ResNet,ResNet,Server,24094.4,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,queries/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),ResNet,ResNet,Server,521.94985,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),ResNet,ResNet,Offline,27298.7,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),ResNet,ResNet,Offline,566.1182069,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,569.89,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,queries/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,516.08095,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,625.244,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,566.6303504,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,44.1866,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,572.8684471,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,44.1866,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,572.8684471,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),RNN-T,RNN-T,Server,3302.19,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,queries/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),RNN-T,RNN-T,Server,540.3120667,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),RNN-T,RNN-T,Offline,9118.73,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),RNN-T,RNN-T,Offline,589.2876934,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,1849.4,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,queries/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,575.9031074,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,2181.27,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,588.1000448,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,839.96,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,queries/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,583.2093884,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,1063.06,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,577.3839533,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,125518,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,queries/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,573.8927167,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,196262,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,580.8154626,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,125518,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,queries/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,573.8927167,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,196262,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,samples/s,2
1.1-014,Dell,datacenter,Dell EMC PowerEdge XE2420 (2x A10; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,580.8154626,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA A10,2,TensorRT 8.0.2; CUDA 11.3,,ECC on,v1.1,9/22/2021,Inference v1.1,System Power (W),2
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),ResNet,ResNet,Server,140021,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),ResNet,ResNet,Server,2092.984667,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),ResNet,ResNet,Offline,161361,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),ResNet,ResNet,Offline,2412.509724,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),SSD-Large,SSD-Large,Server,3962.46,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),SSD-Large,SSD-Large,Server,2830.067833,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),SSD-Large,SSD-Large,Offline,4123.59,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),SSD-Large,SSD-Large,Offline,3031.54006,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),RNN-T,RNN-T,Server,55204.1,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),RNN-T,RNN-T,Server,2629.917637,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),RNN-T,RNN-T,Offline,55448.7,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),RNN-T,RNN-T,Offline,2650.045566,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),BERT-99.0,BERT-99.0,Server,13791.7,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),BERT-99.0,BERT-99.0,Server,3245.761285,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),BERT-99.0,BERT-99.0,Offline,15255.5,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),BERT-99.0,BERT-99.0,Offline,3133.514946,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),BERT-99.9,BERT-99.9,Server,6902.14,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),BERT-99.9,BERT-99.9,Server,3139.308237,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),BERT-99.9,BERT-99.9,Offline,7529.33,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),BERT-99.9,BERT-99.9,Offline,3115.737291,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),DLRM-99.0,DLRM-99.0,Server,1200750,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),DLRM-99.0,DLRM-99.0,Server,2796.349333,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),DLRM-99.0,DLRM-99.0,Offline,1337490,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),DLRM-99.0,DLRM-99.0,Offline,3135.114286,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),DLRM-99.9,DLRM-99.9,Server,1200750,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),DLRM-99.9,DLRM-99.9,Server,2796.349333,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),DLRM-99.9,DLRM-99.9,Offline,1337490,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-016,Dell,datacenter,Dell EMC PowerEdge XE8545 (4x A100-SXM-80GB; TensorRT),DLRM-99.9,DLRM-99.9,Offline,3135.114286,1.0,AMD EPYC 7763,2.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.2; CUDA 11.3,,500W A100-SXM-80GB,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),ResNet,ResNet,Server,185034,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),ResNet,ResNet,Server,2108.429333,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),ResNet,ResNet,Offline,211436,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),ResNet,ResNet,Offline,1887.275968,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,5702.98,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,2179.045833,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,5866.37,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,2164.566922,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,345.121,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,1936.396747,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,345.121,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,1936.396747,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),RNN-T,RNN-T,Server,75011.9,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),RNN-T,RNN-T,Server,2265.875667,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),RNN-T,RNN-T,Offline,84727.3,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),RNN-T,RNN-T,Offline,2203.948645,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,17496.3,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,2188.963667,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,20400.6,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,2489.721591,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,7501.09,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,2148.709667,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,10049.7,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-037,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,2493.405858,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,232036,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,2932.081167,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,244537,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,2946.195088,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,6301.42,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,3163.006833,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,6481.98,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,3171.414861,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,398.739,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,2960.709811,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,398.739,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,2960.709811,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,88013.5,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,3457.184833,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,90242.9,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,3253.906439,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,21496.8,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,3454.947525,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,24667,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,3549.274346,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,10001.9,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3409.112521,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,12131.7,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,3560.578922,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,2002040,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,3383.137333,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,2091060,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,3324.244591,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,2002040,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,3383.137333,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,2091060,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-048,NVIDIA,datacenter,NVIDIA DGX A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,3324.244591,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,107013,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,1129.553333,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,125232,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,1129.203111,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,3082.76,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,1237.269167,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,3295.44,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,1245.219376,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,202.84,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,1150.993575,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,202.84,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,1150.993575,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,43406.1,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,1293.797,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,44494.9,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,1180.320506,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,10202.6,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,1274.363833,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,10573.1,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,1243.403365,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,4301.74,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,1263.32213,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,5170.39,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,1243.310485,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,890424,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,1324.683833,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,987260,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,1254.988939,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,890424,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,queries/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,1324.683833,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,987260,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,samples/s,4
1.1-051,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,1254.988939,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4,TensorRT 8.0.1; CUDA 11.3,,,v1.1,9/22/2021,Inference v1.1,System Power (W),4
1.1-056,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,ResNet,ResNet,Server,310064,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,queries/s,16
1.1-056,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,ResNet,ResNet,Server,1790.982667,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),16
1.1-056,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,ResNet,ResNet,Offline,342011,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,samples/s,16
1.1-056,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,ResNet,ResNet,Offline,1844.484914,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),16
1.1-056,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,SSD-Large,SSD-Large,Server,6868.05,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,queries/s,16
1.1-056,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,SSD-Large,SSD-Large,Server,1917.734667,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),16
1.1-056,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,SSD-Large,SSD-Large,Offline,6958.41,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,samples/s,16
1.1-056,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,SSD-Large,SSD-Large,Offline,1927.84031,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),16
1.1-057,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,BERT-99.0,BERT-99.0,Server,10303.3,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,queries/s,16
1.1-057,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,BERT-99.0,BERT-99.0,Server,1732.2905,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),16
1.1-057,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,BERT-99.0,BERT-99.0,Offline,10601.9,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,samples/s,16
1.1-057,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,BERT-99.0,BERT-99.0,Offline,1712.094545,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),16
1.1-057,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,BERT-99.9,BERT-99.9,Server,5102.64,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,queries/s,16
1.1-057,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,BERT-99.9,BERT-99.9,Server,1819.169833,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),16
1.1-057,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,BERT-99.9,BERT-99.9,Offline,5508.44,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,samples/s,16
1.1-057,Qualcomm,datacenter,Gigabyte G292-Z43 16x QAIC100,BERT-99.9,BERT-99.9,Offline,1881.142965,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,16,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),16
1.1-058,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,ResNet,ResNet,Server,144521,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-058,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,ResNet,ResNet,Server,812.0478333,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-058,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,ResNet,ResNet,Offline,169231,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-058,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,ResNet,ResNet,Offline,857.2938462,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-058,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,SSD-Large,SSD-Large,Server,3381.99,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-058,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,SSD-Large,SSD-Large,Server,840.1276667,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-058,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,SSD-Large,SSD-Large,Offline,3469.93,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-058,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,SSD-Large,SSD-Large,Offline,862.7911901,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.6,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-059,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,BERT-99.0,BERT-99.0,Server,4902.82,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-059,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,BERT-99.0,BERT-99.0,Server,765.174,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-059,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,BERT-99.0,BERT-99.0,Offline,5202.88,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-059,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,BERT-99.0,BERT-99.0,Offline,776.2986364,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-059,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,BERT-99.9,BERT-99.9,Server,2250.17,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,queries/s,8
1.1-059,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,BERT-99.9,BERT-99.9,Server,763.9159734,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),8
1.1-059,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,BERT-99.9,BERT-99.9,Offline,2664.14,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,samples/s,8
1.1-059,Qualcomm,datacenter,Gigabyte R282-Z93 8x QAIC100,BERT-99.9,BERT-99.9,Offline,841.4444611,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,8,Qualcomm Cloud AI SDK v1.5.9,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v1.55.5,v1.1,9/22/2021,Inference v1.1,System Power (W),8
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,,,datacenter/closed/Dell/r7515_q4_pro-qaic-v1.8.3.7-aic100,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,ResNet,Server,"93,750.30",1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,queries/s,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,ResNet,Server,516.4555833,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,Power (W),4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,ResNet,Offline,94201.2,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,samples/s,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,ResNet,Offline,511.9063566,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,Power (W),4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,Retinanet,Server,986.64,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,queries/s,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,Retinanet,Server,405.3143333,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,Power (W),4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,Retinanet,Offline,1047.08,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,samples/s,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,Retinanet,Offline,419.3371752,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,Power (W),4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,BERT,Server,"2,724.61",1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,queries/s,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,BERT,Server,454.2713333,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,Power (W),4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,BERT,Offline,3059.8,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,samples/s,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,BERT,Offline,472.3862158,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,Power (W),4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,BERT,Server,1373.07,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,queries/s,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,BERT,Server,430.7930833,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,Power (W),4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,BERT,Offline,1487.12,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,samples/s,4.0
3.0-0016,Dell,datacenter,Dell PowerEdge R7515 (4x QAIC100 Pro),,BERT,Offline,463.7568571,1.0,AMD EPYC 7542 32-Core Processor,1.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,4.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies,v3.0,4/4/2023,Inference v3.0,Power (W),4.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,,,datacenter/closed/NVIDIA/A100-PCIe-80GBx8_TRT_MaxQ,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,,,availableNVIDIA,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,ResNet,Server,203512,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,ResNet,Server,2085.1285,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,ResNet,Offline,256083,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,ResNet,Offline,2049.729969,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,Retinanet,Server,2021.053,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,Retinanet,Server,2021.053,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,Retinanet,Offline,4687.44,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,Retinanet,Offline,2554.026543,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,3D-UNet,Offline,19.7795,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,3D-UNet,Offline,1779.165084,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,3D-UNet,Offline,19.7795,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,3D-UNet,Offline,1779.165084,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,RNN-T,Server,75001,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,RNN-T,Server,2200.486833,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,RNN-T,Offline,78878.3,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,RNN-T,Offline,2020.984627,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,BERT,Server,17299.1,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,BERT,Server,2164.9805,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,BERT,Offline,22396.7,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,BERT,Offline,2524.625218,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,BERT,Server,7503.01,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,BERT,Server,2158.160167,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,BERT,Offline,11268.6,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,BERT,Offline,2535.04705,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Server,2027.4235,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Server,2027.4235,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Offline,1573310,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Offline,2118.605646,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Server,1000520,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Server,2027.4235,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Offline,1573310,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0066,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Offline,2118.605646,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA A100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,,,datacenter/closed/NVIDIA/H100-PCIe-80GBx8_TRT_MaxQ,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,,,availableNVIDIA,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,ResNet,Server,240018,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,ResNet,Server,2213.467,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,ResNet,Offline,353232,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,ResNet,Offline,2219.577415,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,Retinanet,Server,5602.54,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,Retinanet,Server,2311.0305,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,Retinanet,Offline,5975.26,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,Retinanet,Offline,2253.297086,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,3D-UNet,Offline,26.82,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,3D-UNet,Offline,2115.167176,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,3D-UNet,Offline,26.8151,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,3D-UNet,Offline,2115.167176,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,RNN-T,Server,"87,999.50",1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,RNN-T,Server,2218.618136,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,RNN-T,Offline,99209.8,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,RNN-T,Offline,2192.923252,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,BERT,Server,"33,003.60",1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,BERT,Server,3061.409,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,BERT,Offline,39196.3,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,BERT,Offline,2998.330827,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,BERT,Server,25005,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,BERT,Server,2952.665,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,BERT,Offline,33484.4,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,BERT,Offline,3130.687538,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Server,"1,501,100.00",1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Server,2369.849667,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Offline,3046880,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Offline,2741.709419,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Server,1501100,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Server,2369.849667,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Offline,3046880,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0074,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),,DLRM,Offline,2741.709419,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 8.6.0; CUDA 12.0,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,,,datacenter/closed/Qualcomm/g292_z43_q16e-qaic-v1.8.3.7-aic100,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,,,availableQualcomm,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,ResNet,Server,"290,034.00",1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,ResNet,Server,1467.628833,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,ResNet,Offline,329846,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,ResNet,Offline,1565.211044,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,Retinanet,Server,"3,775.19",1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,Retinanet,Server,1186.352167,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,Retinanet,Offline,3884.56,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,Retinanet,Offline,1208.260909,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,BERT,Server,"9,752.50",1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,BERT,Server,1296.423667,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,BERT,Offline,10053,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,BERT,Offline,1302.232322,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,BERT,Server,5527.06,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,BERT,Server,1438.037667,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,BERT,Offline,5716.41,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,16.0
3.0-0092,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),,BERT,Offline,1455.171733,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),16.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,,,datacenter/closed/Qualcomm/g292_z43_q18e-qaic-v1.8.3.7-aic100,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,,,availableQualcomm,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,ResNet,Server,"345,043.00",1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,ResNet,Server,1751.466667,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,ResNet,Offline,361449,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,ResNet,Offline,1829.448554,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,Retinanet,Server,"4,252.12",1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,Retinanet,Server,1380.816,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,Retinanet,Offline,4366.97,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,Retinanet,Offline,1416.322542,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,BERT,Server,"11,000.30",1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,BERT,Server,1525.942833,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,BERT,Offline,11311,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,BERT,Offline,1537.509545,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,BERT,Server,6202.78,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,BERT,Server,1649.901833,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,BERT,Offline,6423.86,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,18.0
3.0-0094,Qualcomm,datacenter,GIGABYTE G292-Z43 (18x QAIC100 Pro; EE),,BERT,Offline,1672.206839,1.0,AMD EPYC 7713 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,18.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),18.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,,,datacenter/closed/Qualcomm/r282_z93_q8e-qaic-v1.8.3.7-aic100,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,,,availableQualcomm,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,ResNet,Server,"145,881.00",1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,ResNet,Server,641.5301667,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,ResNet,Offline,169533,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,ResNet,Offline,701.3091185,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,Retinanet,Server,"1,849.27",1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,Retinanet,Server,482.9639601,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,Retinanet,Offline,1941.58,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,Retinanet,Offline,498.9140091,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,BERT,Server,"4,802.16",1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,BERT,Server,536.7115,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,BERT,Offline,5009.03,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,BERT,Offline,539.4031715,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,BERT,Server,"2,700.13",1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,BERT,Server,587.0565,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,BERT,Offline,2855.99,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0096,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),,BERT,Offline,599.9752656,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.8.3,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,,,datacenter/closed/Neuchips/RecAccel-N3000-32GB-PCIEx8,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,,8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,,,previewNeuchips,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,,8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,DLRM,Server,"856,398.00",1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,DLRM,Server,807.8768333,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,DLRM,Offline,811664,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,DLRM,Offline,785.420546,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,DLRM,Server,856398,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,queries/s,8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,DLRM,Server,807.8768333,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,DLRM,Offline,811664,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,samples/s,8.0
3.0-0132,Neuchips,datacenter,Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE),,DLRM,Offline,785.420546,1.0,AMD EPYC 7452 32-Core Processor,2.0,RecAccel N3000,8.0,,,,v3.0,4/4/2023,Inference v3.0,Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,400094,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,4135.719,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,474849,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,4063.983208,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,8801.85,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,4545.9225,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,10113.7,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,4554.481776,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,38.2934,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,4166.635213,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,38.2934,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,4166.635213,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,112015,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,4400.4225,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,125479,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,4199.925858,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,42416.1,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,5223.899167,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,54050.3,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,5038.227921,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,39214.7,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,5528.2995,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,51006.9,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,5594.38697,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,244023,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,5794.907,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,273527,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,5629.870213,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,244023,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,5794.907,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,273527,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,5629.870213,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Server,48.9784,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Server,3830.868647,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Offline,64.5056,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Offline,3805.444275,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Server,48.9784,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Server,3830.868647,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Offline,64.5056,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0109,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Offline,3805.444275,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,240024,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,2272.529,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,348572,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,2268.11116,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,6303.18,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Server,2347.186833,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,6719.02,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),Retinanet,Retinanet,Offline,2254.602736,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,27.3564,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,2144.749833,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,27.3564,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,2144.749833,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,88023,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,2248.541764,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,98684.6,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,2235.987009,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,33011.5,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,3348.383667,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,39646.9,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,3047.656012,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,28513,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3116.666167,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,34374.1,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,3310.202839,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,132024,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,3049.977333,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,162281,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,2955.391131,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,132024,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,3049.977333,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,162281,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,2955.391131,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Server,40.0132,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Server,2187.311716,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Offline,50.5737,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Offline,2195.34487,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Server,40.0132,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Server,2187.311716,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Offline,50.5737,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0113,NVIDIA,datacenter,Gigabyte G482-Z54 (8x H100-PCIe-80GB; MaxQ; TensorRT),gptj-99.0,gptj-99.0,Offline,2195.34487,1.0,AMD EPYC 7742 64-Core Processor,2.0,NVIDIA H100-PCIe-80GB,8.0,TensorRT 9.0.0; CUDA 12.2,,,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),ResNet,ResNet,Server,328050,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,queries/s,16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),ResNet,ResNet,Server,1417.293167,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),ResNet,ResNet,Offline,337737,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,samples/s,16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),ResNet,ResNet,Offline,1425.31744,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),Retinanet,Retinanet,Server,3804.75,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,queries/s,16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),Retinanet,Retinanet,Server,980.1275,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),Retinanet,Retinanet,Offline,3949.99,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,samples/s,16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),Retinanet,Retinanet,Offline,982.8601796,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Server,9777.31,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,queries/s,16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Server,1091.036833,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Offline,10068.2,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,samples/s,16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Offline,1098.43617,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Server,5354.05,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,queries/s,16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Server,1163.158167,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Offline,5584.38,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,samples/s,16.0
3.1-0123,Qualcomm,datacenter,GIGABYTE G292-Z43 (16x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Offline,1191.472273,1.0,AMD EPYC 7742 64-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,16.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),16.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),ResNet,ResNet,Server,148018,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),ResNet,ResNet,Server,631.2065,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),ResNet,ResNet,Offline,169969,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),ResNet,ResNet,Offline,686.1130898,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),Retinanet,Retinanet,Server,1901.51,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),Retinanet,Retinanet,Server,455.4099834,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),Retinanet,Retinanet,Offline,1975.93,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),Retinanet,Retinanet,Offline,469.2170659,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Server,4804.25,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Server,529.5671667,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Offline,5031.42,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),BERT-99.0,BERT-99.0,Offline,534.6228659,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Server,2778.99,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,queries/s,8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Server,599.4008333,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Offline,2915.72,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,samples/s,8.0
3.1-0124,Qualcomm,datacenter,GIGABYTE R282-Z93 (8x QAIC100 Pro; EE),BERT-99.9,BERT-99.9,Offline,617.1113178,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe/HHHL Pro,8.0,QUALCOMM Cloud AI SDK v1.9.1,,With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by the KRAI X and KILT technologies,v3.1,9/8/2023,Inference v3.1,System Power (W),8.0
1.0-70,Dell EMC,datacenter,Dell EMC PowerEdge R7525 (3x A100-PCIe),ResNet,ResNet,Server,77976.7,1.0,AMD EPYC 7502,2.0,NVIDIA A100-PCIe-40GB,3.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,3.0
1.0-70,Dell EMC,datacenter,Dell EMC PowerEdge R7525 (3x A100-PCIe),ResNet,ResNet,Server,1097.377167,1.0,AMD EPYC 7502,2.0,NVIDIA A100-PCIe-40GB,3.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),3.0
1.0-70,Dell EMC,datacenter,Dell EMC PowerEdge R7525 (3x A100-PCIe),ResNet,ResNet,Offline,93371.4,1.0,AMD EPYC 7502,2.0,NVIDIA A100-PCIe-40GB,3.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,3.0
1.0-70,Dell EMC,datacenter,Dell EMC PowerEdge R7525 (3x A100-PCIe),ResNet,ResNet,Offline,1101.282834,1.0,AMD EPYC 7502,2.0,NVIDIA A100-PCIe-40GB,3.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),3.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),ResNet,ResNet,Server,21691.3,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),ResNet,ResNet,Server,792.694,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),ResNet,ResNet,Offline,23309.3,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),ResNet,ResNet,Offline,794.4642655,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),SSD-Large,SSD-Large,Server,500.963,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),SSD-Large,SSD-Large,Server,790.8251667,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),SSD-Large,SSD-Large,Offline,557.434,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),SSD-Large,SSD-Large,Offline,792.8532394,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),RNN-T,RNN-T,Server,4202.02,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),RNN-T,RNN-T,Server,862.4563333,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),RNN-T,RNN-T,Offline,5704.6,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),RNN-T,RNN-T,Offline,856.7994693,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),DLRM-99.0,DLRM-99.0,Server,126531,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),DLRM-99.0,DLRM-99.0,Server,835.9083333,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),DLRM-99.0,DLRM-99.0,Offline,135189,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),DLRM-99.0,DLRM-99.0,Offline,830.1261295,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),DLRM-99.9,DLRM-99.9,Server,126531,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),DLRM-99.9,DLRM-99.9,Server,835.523,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),DLRM-99.9,DLRM-99.9,Offline,135149,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-71,Dell EMC,datacenter,Dell EMC PowerEdge XE2420 (4x T4),DLRM-99.9,DLRM-99.9,Offline,829.085854,1.0,Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz,2.0,NVIDIA T4,4.0,TensorRT 7.2.3; CUDA 11.1,,ECC on,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),ResNet,ResNet,Server,184984,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),ResNet,ResNet,Server,2245.331,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),ResNet,ResNet,Offline,213599,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),ResNet,ResNet,Offline,2195.056765,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,5701.91,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,2259.641333,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,5823.76,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,2244.0586,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,372.133,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,2260.884779,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,372.133,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,2260.884779,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),RNN-T,RNN-T,Server,74974.3,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),RNN-T,RNN-T,Server,2324.844833,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),RNN-T,RNN-T,Offline,82539.5,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),RNN-T,RNN-T,Offline,2278.421562,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,17498.5,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,2308.857833,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,17696.9,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,2289.977381,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,7504.02,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,2263.458902,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,8645.52,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-72,NVIDIA,datacenter,Gigabyte G482-Z54 (8x A100-PCIe; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,2300.079344,1.0,AMD EPYC 7742,2.0,NVIDIA A100-PCIe-40GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,239991,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,3451.695667,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,270706,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,3458.685495,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,6301.4,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,3459.557167,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,6874.84,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,3503.110027,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,433.361,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,3494.184679,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,433.361,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,3494.184679,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,87983.7,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,3550.964393,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,93803.2,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,3555.000137,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,21491.7,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,3563.515842,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,23405.6,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,3457.682742,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,10002.7,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,3506.393729,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,10879.6,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,3467.838571,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,2001940,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,3477.295333,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,2115950,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,3415.354011,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,2001940,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,3477.295333,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,2115950,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,8.0
1.0-73,NVIDIA,datacenter,NVIDIA DGX-A100 (8x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,3415.354011,1.0,AMD EPYC 7742,2.0,NVIDIA A100-SXM-80GB,8.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),8.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,106988,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Server,1266.027833,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,124529,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),ResNet,ResNet,Offline,1268.95177,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,3080.96,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Server,1266.861,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,3109.64,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),SSD-Large,SSD-Large,Offline,1275.109571,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,202.348,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.0,3D-UNet-99.0,Offline,1285.380919,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,202.348,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),3D-UNet-99.9,3D-UNet-99.9,Offline,1285.380919,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,43388.9,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Server,1313.53777,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,47254.9,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),RNN-T,RNN-T,Offline,1306.809687,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,10202.9,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Server,1301.990667,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,9865.37,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.0,BERT-99.0,Offline,1272.073094,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,4302.49,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Server,1295.017,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,4787.66,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),BERT-99.9,BERT-99.9,Offline,1268.977649,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,890334,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Server,1341.6335,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,974571,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.0,DLRM-99.0,Offline,1277.892614,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,890334,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,queries/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Server,1341.6335,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,974571,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,samples/s,4.0
1.0-74,NVIDIA,datacenter,NVIDIA DGX Station A100 (4x A100-SXM-80GB; MaxQ; TensorRT),DLRM-99.9,DLRM-99.9,Offline,1277.892614,1.0,AMD EPYC 7742,1.0,NVIDIA A100-SXM-80GB,4.0,TensorRT 7.2.3; CUDA 11.1,,,v1.0,4/17/2021,Inference v1.0,System Power (W),4.0
1.0-75,Qualcomm,datacenter,Gigabyte R282-Z93 5x QAIC100,ResNet,ResNet,Server,78501.9,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,5.0,Qualcomm Cloud AI SDK v1.3.14,,With 75W Accelerator TDP constraints Powered by Collective Knowledge 1.55.2,v1.0,4/17/2021,Inference v1.0,queries/s,5.0
1.0-75,Qualcomm,datacenter,Gigabyte R282-Z93 5x QAIC100,ResNet,ResNet,Server,533.812,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,5.0,Qualcomm Cloud AI SDK v1.3.14,,With 75W Accelerator TDP constraints Powered by Collective Knowledge 1.55.2,v1.0,4/17/2021,Inference v1.0,System Power (W),5.0
1.0-75,Qualcomm,datacenter,Gigabyte R282-Z93 5x QAIC100,ResNet,ResNet,Offline,100077,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,5.0,Qualcomm Cloud AI SDK v1.3.14,,With 75W Accelerator TDP constraints Powered by Collective Knowledge 1.55.2,v1.0,4/17/2021,Inference v1.0,samples/s,5.0
1.0-75,Qualcomm,datacenter,Gigabyte R282-Z93 5x QAIC100,ResNet,ResNet,Offline,561.9439394,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,5.0,Qualcomm Cloud AI SDK v1.3.14,,With 75W Accelerator TDP constraints Powered by Collective Knowledge 1.55.2,v1.0,4/17/2021,Inference v1.0,System Power (W),5.0
1.0-75,Qualcomm,datacenter,Gigabyte R282-Z93 5x QAIC100,SSD-Large,SSD-Large,Server,1557.43,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,5.0,Qualcomm Cloud AI SDK v1.3.14,,With 75W Accelerator TDP constraints Powered by Collective Knowledge 1.55.2,v1.0,4/17/2021,Inference v1.0,queries/s,5.0
1.0-75,Qualcomm,datacenter,Gigabyte R282-Z93 5x QAIC100,SSD-Large,SSD-Large,Server,547.8265,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,5.0,Qualcomm Cloud AI SDK v1.3.14,,With 75W Accelerator TDP constraints Powered by Collective Knowledge 1.55.2,v1.0,4/17/2021,Inference v1.0,System Power (W),5.0
1.0-75,Qualcomm,datacenter,Gigabyte R282-Z93 5x QAIC100,SSD-Large,SSD-Large,Offline,1777.91,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,5.0,Qualcomm Cloud AI SDK v1.3.14,,With 75W Accelerator TDP constraints Powered by Collective Knowledge 1.55.2,v1.0,4/17/2021,Inference v1.0,samples/s,5.0
1.0-75,Qualcomm,datacenter,Gigabyte R282-Z93 5x QAIC100,SSD-Large,SSD-Large,Offline,598.0932635,1.0,AMD EPYC 7282 16-Core Processor,2.0,QUALCOMM Cloud AI 100 PCIe HHHL,5.0,Qualcomm Cloud AI SDK v1.3.14,,With 75W Accelerator TDP constraints Powered by Collective Knowledge 1.55.2,v1.0,4/17/2021,Inference v1.0,System Power (W),5.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),3d-unet-99.0,3d-unet-99.0,Offline,37.35,1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),3d-unet-99.0,3d-unet-99.0,Offline,"4,101.59",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),3d-unet-99.9,3d-unet-99.9,Offline,37.35,1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),3d-unet-99.9,3d-unet-99.9,Offline,"4,101.59",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.0,gptj-99.0,Offline,173.95,1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.0,gptj-99.0,Offline,"4,611.84",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.0,gptj-99.0,Server,149.90,1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.0,gptj-99.0,Server,"4,596.00",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.9,gptj-99.9,Offline,173.95,1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.9,gptj-99.9,Offline,"4,611.84",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.9,gptj-99.9,Server,149.90,1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.9,gptj-99.9,Server,"4,596.00",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),llama2-70b-99.9,llama2-70b-99.9,Offline,"17,098.60",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Tokens/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),llama2-70b-99.9,llama2-70b-99.9,Offline,"5,722.27",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),llama2-70b-99.9,llama2-70b-99.9,Server,"14,369.73",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Tokens/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),llama2-70b-99.9,llama2-70b-99.9,Server,"5,741.12",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),resnet50,resnet,Offline,"456,575.00",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),resnet50,resnet,Offline,"4,037.99",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),resnet50,resnet,Server,"400,031.00",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),resnet50,resnet,Server,"3,894.29",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Offline,9.25,1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Offline,"4,600.85",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Server,8.78,1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0033,Dell,datacenter,Dell PowerEdge XE9680 (8x H100-SXM-80GB MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Server,"4,473.48",1.0,Intel(R) Xeon(R) Platinum 8470,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 22.04.3,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0042,Fujitsu,datacenter,PRIMERGY CDI (8x L40S MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Offline,4.24,1.0,Intel(R) Xeon(R) Platinum 8452Y,2.0,NVIDIA L40S,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,GPU Power Limit: 280W,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0042,Fujitsu,datacenter,PRIMERGY CDI (8x L40S MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Offline,"3,572.72",1.0,Intel(R) Xeon(R) Platinum 8452Y,2.0,NVIDIA L40S,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,GPU Power Limit: 280W,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0042,Fujitsu,datacenter,PRIMERGY CDI (8x L40S MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Server,4.12,1.0,Intel(R) Xeon(R) Platinum 8452Y,2.0,NVIDIA L40S,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,GPU Power Limit: 280W,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0042,Fujitsu,datacenter,PRIMERGY CDI (8x L40S MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Server,"3,509.58",1.0,Intel(R) Xeon(R) Platinum 8452Y,2.0,NVIDIA L40S,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,GPU Power Limit: 280W,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),3d-unet-99.0,3d-unet-99.0,Offline,38.21,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),3d-unet-99.0,3d-unet-99.0,Offline,"4,220.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),3d-unet-99.9,3d-unet-99.9,Offline,38.21,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),3d-unet-99.9,3d-unet-99.9,Offline,"4,220.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),bert-99.0,bert-99.0,Offline,"53,726.90",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),bert-99.0,bert-99.0,Offline,"5,080.34",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),bert-99.0,bert-99.0,Server,"42,386.40",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),bert-99.0,bert-99.0,Server,"5,307.77",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),bert-99.9,bert-99.9,Offline,"50,998.90",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),bert-99.9,bert-99.9,Offline,"5,646.60",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),bert-99.9,bert-99.9,Server,"39,186.70",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),bert-99.9,bert-99.9,Server,"5,610.87",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,"458,408.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Offline,"5,694.45",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,"400,031.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),dlrm-v2-99.0,dlrm-v2-99.0,Server,"5,960.32",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),dlrm-v2-99.9,dlrm-v2-99.9,Offline,"283,714.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),dlrm-v2-99.9,dlrm-v2-99.9,Offline,"5,621.38",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),dlrm-v2-99.9,dlrm-v2-99.9,Server,"255,995.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),dlrm-v2-99.9,dlrm-v2-99.9,Server,"5,822.31",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.0,gptj-99.0,Offline,178.90,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.0,gptj-99.0,Offline,"4,790.59",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.0,gptj-99.0,Server,149.90,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.0,gptj-99.0,Server,"4,833.75",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.9,gptj-99.9,Offline,178.90,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.9,gptj-99.9,Offline,"4,790.59",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.9,gptj-99.9,Server,149.90,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),gptj-99.9,gptj-99.9,Server,"4,833.75",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),llama2-70b-99.9,llama2-70b-99.9,Offline,"17,561.60",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Tokens/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),llama2-70b-99.9,llama2-70b-99.9,Offline,"5,888.19",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),llama2-70b-99.9,llama2-70b-99.9,Server,"15,487.46",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Tokens/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),llama2-70b-99.9,llama2-70b-99.9,Server,"5,908.76",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),resnet50,resnet,Offline,"473,737.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),resnet50,resnet,Offline,"4,115.42",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),resnet50,resnet,Server,"400,031.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),resnet50,resnet,Server,"4,176.64",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),retinanet,retinanet,Offline,"10,105.90",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),retinanet,retinanet,Offline,"4,597.22",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),retinanet,retinanet,Server,"8,794.18",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),retinanet,retinanet,Server,"4,589.93",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),rnnt,rnnt,Offline,"139,938.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),rnnt,rnnt,Offline,"4,430.82",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),rnnt,rnnt,Server,"123,981.00",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),rnnt,rnnt,Server,"4,559.57",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Offline,9.65,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Samples/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Offline,"4,751.58",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Server,8.78,1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Queries/s,8.0
4.0-0063,NVIDIA,datacenter,NVIDIA DGX H100 (8x H100-SXM-80GB MaxQ TensorRT),stable-diffusion-xl,stable-diffusion-xl,Server,"4,489.83",1.0,Intel(R) Xeon(R) Platinum 8480C,2.0,NVIDIA H100-SXM-80GB,8.0,TensorRT 9.3.0 CUDA 12.2,Ubuntu 20.04.4,,v4.0,3/26/2024,Inference v4.0,Watts,8.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),bert-99.0,bert-99.0,Offline,"30,022.20",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Samples/s,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),bert-99.0,bert-99.0,Offline,"2,953.58",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Watts,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),bert-99.0,bert-99.0,Server,"26,495.20",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Queries/s,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),bert-99.0,bert-99.0,Server,"2,674.80",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Watts,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),bert-99.9,bert-99.9,Offline,"16,511.00",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Samples/s,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),bert-99.9,bert-99.9,Offline,"3,222.52",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Watts,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),bert-99.9,bert-99.9,Server,"14,120.50",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Queries/s,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),bert-99.9,bert-99.9,Server,"2,875.13",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Watts,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),resnet50,resnet,Offline,"887,855.00",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Samples/s,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),resnet50,resnet,Offline,"3,226.02",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Watts,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),resnet50,resnet,Server,"575,143.00",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Queries/s,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),resnet50,resnet,Server,"3,483.33",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Watts,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),retinanet,retinanet,Offline,"15,105.10",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Samples/s,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),retinanet,retinanet,Offline,"2,912.38",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Watts,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),retinanet,retinanet,Server,"12,495.80",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Queries/s,16.0
4.0-0074,Qualcomm,datacenter,GIGABYTE G293-Z43 (16x QAIC100 Ultra EE),retinanet,retinanet,Server,"2,621.50",1.0,AMD EPYC 9554 64-Core Processor,2.0,QUALCOMM Cloud AI 100 Ultra,16.0,QUALCOMM Cloud AI SDK v1.12.2,Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux),Powered by the KRAI X and KILT technologies,v4.0,3/26/2024,Inference v4.0,Watts,16.0
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,3d-unet-99,Offline,4613.61938326,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,3d-unet-99,Offline,41.664,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,3d-unet-99.9,Offline,4613.61938326,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,3d-unet-99.9,Offline,41.664,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,bert-99.0,Offline,5531.247344461,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,bert-99.0,Offline,54063.2,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,bert-99,Server,5235.63,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,bert-99,Server,41599.4,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,bert-99.9,Offline,5628.787707182,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,bert-99.9,Offline,46534.6,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,bert-99.9,Server,5639.263333333,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,bert-99.9,Server,39804.3,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,dlrm-v2-99.0,Offline,5997.418914474,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,dlrm-v2-99.0,Offline,503719.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,dlrm-v2-99,Server,6068.71,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,dlrm-v2-99,Server,420107.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,dlrm-v2-99.9,Offline,6035.110518519,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,dlrm-v2-99.9,Offline,305223.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,dlrm-v2-99.9,Server,6064.625,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,dlrm-v2-99.9,Server,280045.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,gptj-99.0,Offline,4775.270359848,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,gptj-99.0,Offline,13096.6,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,gptj-99,Server,4722.561172742,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,gptj-99,Server,11700.8,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,gptj-99.9,Offline,4775.270359848,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,gptj-99.9,Offline,13096.6,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,gptj-99.9,Server,4722.561172742,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,gptj-99.9,Server,11700.8,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,llama2-70b-99.0,Offline,6152.984435173,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,llama2-70b-99.0,Offline,25262.1,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,llama2-70b-99,Server,6280.214,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,llama2-70b-99,Server,23113.14,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,llama2-70b-99.9,Offline,6152.984435173,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,llama2-70b-99.9,Offline,25262.1,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,llama2-70b-99.9,Server,6280.214,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,llama2-70b-99.9,Server,23113.14,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,mixtral-8x7b,Offline,6154.803549383,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,mixtral-8x7b,Offline,48987.9,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,mixtral-8x7b,Server,6174.896328383,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,mixtral-8x7b,Server,45497.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Tokens/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,resnet,Offline,4954.031546707,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,resnet,Offline,556234.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,resnet,Server,5013.791166667,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,resnet,Server,480131.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,retinanet,Offline,5019.128805237,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,retinanet,Offline,10802.5,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,retinanet,Offline,4987.039666667,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,retinanet,Offline,9602.95,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,stable-diffusion-xl,Offline,5573.811127596,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,stable-diffusion-xl,Offline,13.202,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,stable-diffusion-xl,Server,5487.744754098,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,stable-diffusion-xl,Server,12.708,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,resnet,Offline,1021.358974359,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,resnet,Offline,334462.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,resnet,Server,985.519134775,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Watts,8
4.1-0049,NVIDIA,datacenter,NVIDIA H200 (8x H200-SXM-141GB MaxQ TensorRT),Intel(R) Xeon(R) Platinum 8480C,resnet,Server,309752.0,1,Intel(R) Xeon(R) Platinum 8480C,56,NVIDIA H200-SXM-141GB,8,,,,v4.1,8/28/2024,,Samples/s,8
4.1-0066,UntetherAI,datacenter,Dell PowerEdge R760xa (6x speedAI240 Slim),Intel(R) Xeon(R) Gold 6448Y,resnet,Offline,4613.61938326,1,Intel(R) Xeon(R) Gold 6448Y,56,UntetherAI speedAI240 Slim,6,,,,v4.1,8/28/2024,,Watts,6
4.1-0066,UntetherAI,datacenter,Dell PowerEdge R760xa (6x speedAI240 Slim),Intel(R) Xeon(R) Gold 6448Y,resnet,Offline,41.664,1,Intel(R) Xeon(R) Gold 6448Y,56,UntetherAI speedAI240 Slim,6,,,,v4.1,8/28/2024,,Queries/s,6
4.1-0066,UntetherAI,datacenter,Dell PowerEdge R760xa (6x speedAI240 Slim),Intel(R) Xeon(R) Gold 6448Y,resnet,Server,4613.61938326,1,Intel(R) Xeon(R) Gold 6448Y,56,UntetherAI speedAI240 Slim,6,,,,v4.1,8/28/2024,,Watts,6
4.1-0066,UntetherAI,datacenter,Dell PowerEdge R760xa (6x speedAI240 Slim),Intel(R) Xeon(R) Gold 6448Y,resnet,Server,41.664,1,Intel(R) Xeon(R) Gold 6448Y,56,UntetherAI speedAI240 Slim,6,,,,v4.1,8/28/2024,,Queries/s,6
4.1-0066,UntetherAI,datacenter,Dell PowerEdge R760xa (6x speedAI240 Slim),Intel(R) Xeon(R) Gold 6448Y,3d-unet-99,Offline,5531.247344461,1,Intel(R) Xeon(R) Gold 6448Y,56,UntetherAI speedAI240 Slim,6,,,,v4.1,8/28/2024,,Watts,6
4.1-0066,UntetherAI,datacenter,Dell PowerEdge R760xa (6x speedAI240 Slim),Intel(R) Xeon(R) Gold 6448Y,3d-unet-99,Offline,54063.2,1,Intel(R) Xeon(R) Gold 6448Y,56,UntetherAI speedAI240 Slim,6,,,,v4.1,8/28/2024,,Tokens/s,6
4.1-0066,UntetherAI,datacenter,Dell PowerEdge R760xa (6x speedAI240 Slim),Intel(R) Xeon(R) Gold 6448Y,3d-unet-99.9,Server,5235.63,1,Intel(R) Xeon(R) Gold 6448Y,56,UntetherAI speedAI240 Slim,6,,,,v4.1,8/28/2024,,Watts,6
4.1-0066,UntetherAI,datacenter,Dell PowerEdge R760xa (6x speedAI240 Slim),Intel(R) Xeon(R) Gold 6448Y,3d-unet-99.9,Server,41599.4,1,Intel(R) Xeon(R) Gold 6448Y,56,UntetherAI speedAI240 Slim,6,,,,v4.1,8/28/2024,,Tokens/s,6
